#!/usr/bin/env python3

# Run benchmarks and compare the results interactively.

import argparse
import copy
import json
import math
import os
import os.path
import platform
import random
import re
import subprocess
import sys
import threading
import time
import tempfile
import queue

LibDir = os.path.join(os.path.dirname(__file__), 'lib')
sys.path.insert(0, LibDir)

import android
from build import Build
from format import *
from perf import *
from stats import *
from test import *
from utils import DelayedKeyboardInterrupt
import display
import gcprofile
from getch import KeyGetter

CompareKeys = ['min', 'mean', 'median', 'max', 'cofv']

def main():
    args = parseArgs()
    builds = buildsToTest(args)
    tests = testsToRun(args)
    if args.android:
        android.init(builds, tests, args)
    runTests(args, builds, tests)

def parseArgs():
    parser = argparse.ArgumentParser(
        description='Run benchmarks and compare the results interactively')
    parser.add_argument('-t', '--test', help='Test suite to run')
    parser.add_argument('--iterations',
                        type=int,
                        default=200,
                        help='The number of times to run each test')
    parser.add_argument('--show-histogram', action='store_true')
    parser.add_argument('--show-samples', action='store_true')
    parser.add_argument('-c', '--compare', choices=CompareKeys, default='mean')
    parser.add_argument('--gc-profile', action='store_true')
    parser.add_argument('--sys-usage', action='store_true')
    parser.add_argument('--perf', action='store_true')
    parser.add_argument('--geomean', action='store_true')
    parser.add_argument('--output',
                        '-o',
                        help='Write results to file in JSON format')
    parser.add_argument('--numa',
                        action='store_true',
                        help='Bind CPU and memory to NUMA node 1')
    parser.add_argument('--args',
                        default='',
                        help='Extra arguments passed to every build')
    parser.add_argument('--gc-param',
                        default='',
                        help='Set a GC parameter for every build')
    parser.add_argument('--repeat-with-gc-params',
                        default='',
                        help='Run a single build with different GC params')
    parser.add_argument('--csv',
                        action='store_true',
                        help='Produce output in CSV format')
    parser.add_argument('--android',
                        action='store_true',
                        help='Run benchmarks on connected Android device')
    parser.add_argument('builds', nargs="+")
    return parser.parse_args()

def buildsToTest(args):
    builds = list(map(Build, args.builds))

    if args.args:
        extra_args = args.args.split()
        for build in builds:
            build.args.extend(extra_args)

    if args.gc_param:
        extra_args = ['--gc-param', args.gc_param]
        for build in builds:
            build.args.extend(extra_args)

    # Repeat builds for different GC param values if specified.
    if args.repeat_with_gc_params:
        opts = args.repeat_with_gc_params.split('=')
        assert len(opts) == 2
        param, values = opts
        values = values.split(',')
        newBuilds = []
        for build in builds:
            for value in values:
                b = copy.deepcopy(build)
                arg = f"--gc-param={param}={value}"
                b.args.append(arg)
                b.spec += " " + arg
                newBuilds.append(b)
        builds = newBuilds

    return builds

def testsToRun(args):
    allTests = getKnownTests()

    if not args.test:
        return [allTests[0]]

    tests = list(filter(lambda t: t.name == args.test, allTests))
    if tests:
        return tests

    return [LocalTest(args.test)]

def getKnownTests():
    return [
        # Run all tests sequentially in a single runtime.
        OctaneTest(),

        # Run individual tests independently.
        OctaneTest('richards'),
        OctaneTest('deltablue'),
        OctaneTest('crypto'),
        OctaneTest('raytrace'),
        OctaneTest('earley-boyer'),
        OctaneTest('regexp'),
        OctaneTest('splay'),
        OctaneTest('navier-stokes'),
        OctaneTest('pdfjs'),
        OctaneTest('mandreel'),
        OctaneTest('gbemu'),
        OctaneTest('code-load'),
        OctaneTest('box2d'),
        OctaneTest('zlib'),
        OctaneTest('typescript')
    ]

def runTests(args, builds, tests):
    # Nested map of lists keyed by result key then by build.
    results = dict()

    out = None
    if sys.stdout.isatty():
        out = display.Terminal()

    with KeyGetter() as keyGetter:
        eventQueue = queue.Queue()
        if sys.stdout.isatty():
            startKeyboardInputThread(eventQueue, keyGetter)
        startTestRunnerThread(eventQueue, args, builds, tests)

        while True:
            event = eventQueue.get()
            if event is None:
                break  # Finished.
            elif isinstance(event, TestResults):
                addResults(builds, results, event.build, event.results)
            else:
                assert isinstance(event, KeyPress)
                if not handleKeyPress(args, event.key):
                    break  # Quit

            if out:
                with DelayedKeyboardInterrupt():
                    displayResults(out, builds, results, args)

    with DelayedKeyboardInterrupt():
        if args.output:
            writeResultsToFile(builds, results, args)
        if not out:
            out = display.File(sys.stdout)
            displayResults(out, builds, results, args)

def handleKeyPress(args, key):
    # q: quit.
    if key == 'q':
        return False

    # c: cycle through comparision keys.
    if key.lower() == 'c':
        i = CompareKeys.index(args.compare)
        i += 1 if key.islower() else -1
        i = i % len(CompareKeys)
        args.compare = CompareKeys[i]

    # h: toggle show histogram setting
    if key == 'h':
        args.show_histogram = not args.show_histogram
        args.show_samples = False

    # s: toggle show samples setting
    if key == 's':
        args.show_histogram = False
        args.show_samples = not args.show_samples

    # Ignore unknown.
    return True

def startTestRunnerThread(eventQueue, args, builds, tests):
    thread = threading.Thread(target=testRunnerThread,
                              args=(eventQueue, args, builds, tests),
                              daemon=True)
    thread.start()

def testRunnerThread(eventQueue, args, builds, tests):
    for (build, test) in generateTestRuns(args, builds, tests):
        results = runBenchmark(build, test, args)
        eventQueue.put(TestResults(build, results))
    eventQueue.put(None)

class TestResults:
    def __init__(self, build, results):
        self.build = build
        self.results = results

def startKeyboardInputThread(eventQueue, keyGetter):
    thread = threading.Thread(target=keyboardInputThread,
                              args=(eventQueue, keyGetter),
                              daemon=True)
    thread.start()

def keyboardInputThread(eventQueue, keyGetter):
    try:
        while True:
            key = keyGetter.get()
            eventQueue.put(KeyPress(key))
    finally:
        eventQueue.put(None)  # Exit on exception.

class KeyPress:
    def __init__(self, key):
        self.key = key

def generateTestRuns(args, builds, tests):
    for i in range(args.iterations):
        for build in shuffled(builds):
            for test in shuffled(tests):
                yield (build, test)

def shuffled(list):
    result = list.copy()
    random.shuffle(result)
    return result

def runBenchmark(build, test, args):
    cmd = [build.shell] + build.args + [test.script] + test.args
    env = dict()

    profilePath = None
    if args.gc_profile:
        if args.android:
            profilePath = android.getProfilePath()
        else:
            temp = tempfile.NamedTemporaryFile(delete=False)
            temp.close()
            profilePath = temp.name
        env['JS_GC_PROFILE'] = '0'
        env['JS_GC_PROFILE_NURSERY'] = '0'
        env['JS_GC_PROFILE_FILE'] = profilePath

    if args.numa:
        cmd = ['numactl', '--cpunodebind=1', '--localalloc', '--'] + cmd

    if args.sys_usage:
        flag = "-l" if platform.system() == "Darwin" else "-v"
        path = "/system/bin" if args.android else "/usr/bin"
        cmd = [f'{path}/time', flag] + cmd
    elif args.perf:
        cmd = updateCommandForPerf(args, cmd)

    if not args.android:
        # On Android pausing scales down CPU frequency for inactivity.
        time.sleep(0.2)

    if args.android:
        stdout, stderr = android.runRemote(build, test.dir, cmd, env)
    else:
        oldcwd = os.getcwd()
        os.chdir(test.dir)

        proc = subprocess.run(cmd, env=env, capture_output=True, text=True)
        if proc.returncode != 0:
            print(
                f"Error running benchmark {test.name} with shell {build.shell}:"
            )
            print(' '.join(cmd))
            print(f"Command exited with return code {proc.returncode}")
            print(proc.stderr)
            sys.exit(1)
        stdout, stderr = proc.stdout, proc.stderr

        os.chdir(oldcwd)

    return parseOutput(stdout, stderr, args, profilePath)

def parseOutput(stdout, stderr, args, profilePath):
    results = dict()

    for line in stdout.splitlines():
        match = re.match(r'([\w\s]+):\s+(\d+(:?\.\d+)?)', line)
        if match:
            key, value = match.group(1), match.group(2)
            key = '!' + key  # These are displayed first.
            value = float(value)
            if key not in results:
                results[key] = []
            results[key].append(value)

    # if args.android:
    #     results["Max CPU frequency"] = android.getMaxCpuFrequency()

    if profilePath:
        if args.android:
            profileData = android.readProfile(profilePath)
        else:
            with open(profilePath) as f:
                profileData = f.read()
            os.remove(profilePath)
        gcprofile.summariseProfile(profileData, results, False)

    if args.sys_usage:
        parseSysUsage(results, stderr)

    if args.perf:
        parsePerfOutput(results, stdout, stderr, args)

    if not results:
        print("Failed to parse any result from output:")
        print(stdout + stderr)
        # bug: this doesn't cause the main program to exit any more
        sys.exit(1)

    return results

def parseSysUsage(results, text):
    for line in text.splitlines():
        line = line.strip()
        if line == "":
            continue

        if platform.system() == "Darwin":
            parts = line.split()
            if parts[1] == "real" and parts[3] == "user" and parts[5] == "sys":
                addSysUsageResult(results, "Real time", parts[0])
                addSysUsageResult(results, "User time", parts[2])
                addSysUsageResult(results, "System time", parts[4])
                continue
            value = parts[0]
            key = " ".join(parts[1:])
        else:
            key, value = line.split(": ")

        addSysUsageResult(results, key, value)

def addSysUsageResult(results, key, value):
    if value.endswith("%"):
        value = int(value[:-1])
    elif ":" in value:
        hours, minsAndSecs = value.split(":")
        value = int(hours) * 60 + float(minsAndSecs)
    elif re.match(r"\d+(\.\d+)?$", value):
        value = float(value)
    else:
        return

    if platform.system() == "Darwin" and "size" in key:
        value = value / 1024
        key += " (KB)"

    results[key] = value

def addResults(builds, results, build, newResults):
    for key in newResults.keys():
        if key not in results:
            results[key] = dict()
            for b in builds:
                results[key][b] = []

        result = newResults[key]
        if isinstance(result, list):
            for value in result:
                addResult(results, build, key, value)
        else:
            addResult(results, build, key, result)

def addResult(results, build, key, result):
    results[key][build].append(result)

def displayResults(out, builds, results, args):
    out.clear()
    if not args.csv:
        printHeader(out, args)

    if args.geomean:
        geomean = dict()
        for build in builds:
            geomean[build] = (0, 0)

    for key in results.keys():
        isResultKey = key.startswith('!')
        keyName = key[1:] if isResultKey else key

        statsForBuild = dict()
        compareTo = None
        low = None
        high = None
        first = True

        for build in builds:
            data = results[key][build]
            if not data:
                continue

            stats = Stats(data)
            statsForBuild[build] = stats

            if args.geomean and isResultKey and stats.mean != 0:
                sumOfLogs, count = geomean[build]
                geomean[build] = (sumOfLogs + math.log(stats.mean), count + 1)

            if first:
                compareTo = stats
                low, high = stats.min, stats.max
                first = False
            else:
                low, high = min(low, stats.min), max(high, stats.max)

        if not statsForBuild or (low == high and not isResultKey):
            continue

        if not args.csv:
            out.print(f"{keyName}:")

        for build in statsForBuild.keys():
            stats = statsForBuild[build]
            comp = compareStats(stats, compareTo, args.compare)
            text = formatStats(stats, comp, args)

            if not args.csv and stats.count > 1 and low != high:
                text += "  " + formatBox(low, high, stats)
                if args.show_histogram:
                    text += "  " + formatHistogram(low, high, stats)
                if args.show_samples:
                    text += "  " + formatSamples(low, high, stats)

            if args.csv:
                out.print("%s, %s, %s" % (keyName, build.spec, text))
            else:
                out.print("  %20s  %s" % (build.spec[-20:], text))

    if args.geomean and not args.csv:
        out.print()
        out.print("Geometric mean of means:")
        compareTo = None
        first = True
        for build in builds:
            sumOfLogs, count = geomean[build]
            if count != 0:
                mean = math.exp(sumOfLogs / count)
                text = "          %8s" % formatFloat(8, mean)
                if first:
                    compareTo = mean
                    first = False
                else:
                    diff = (mean - compareTo) / compareTo
                    text += "                                     %4.1f%%" % (
                        diff * 100)
                out.print("  %20s  %s" % (build.spec[-20:], text))

def printHeader(out, args):
    header = (24 * " ") + statsHeader(args.compare)
    width = len(header)
    out.print(header)
    out.print(width * "=")

def writeResultsToFile(builds, results, args):
    data = []
    for build in builds:
        buildData = {
            'build': build.spec,
            'system': platform.system(),
            'architecture': platform.machine(),
            'results': dict()
        }

        for key in results.keys():
            if build in results[key]:
                stats = Stats(results[key][build])
                if key.startswith('!'):
                    key = key[1:]
                buildData['results'][key] = stats.__dict__

        data.append(buildData)

    with open(args.output, "w") as f:
        json.dump(data, f, allow_nan=False, indent=2)

try:
    main()
except KeyboardInterrupt:
    pass
